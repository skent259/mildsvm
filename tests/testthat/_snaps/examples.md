# `build_fm()`, `kfm_exact()`, `kfm_nystrom()` examples work

    Code
      df <- data.frame(X1 = c(2, 3, 4, 5, 6, 7, 8), X2 = c(1, 1.2, 1.3, 1.4, 1.1, 7,
        1), X3 = rnorm(7))
      fit1 <- kfm_nystrom(df, m = 7, r = 6, kernel = "radial", sigma = 0.05)
      fm <- build_fm(fit1, df)
      fit2 <- kfm_exact(kernel = "polynomial", degree = 2, const = 1)
      fm <- build_fm(fit2, df)

# `cv_misvm()` examples work

    Code
      set.seed(8)
      mil_data <- generate_mild_df(nbag = 20, positive_prob = 0.15, dist = rep(
        "mvnormal", 3), mean = list(rep(1, 10), rep(2, 10)), sd_of_mean = rep(0.1, 3))
      df <- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))
      cost_seq <- 2^seq(-5, 7, length.out = 3)
      mdl1 <- cv_misvm(x = df[, 4:123], y = df$bag_label, bags = df$bag_name,
      cost_seq = cost_seq, n_fold = 3, method = "heuristic")
      mdl2 <- cv_misvm(mi(bag_label, bag_name) ~ X1_mean + X2_mean + X3_mean, data = df,
      cost_seq = cost_seq, n_fold = 3)
      if (require(gurobi)) {
        mdl3 <- cv_misvm(x = df[, 4:123], y = df$bag_label, bags = df$bag_name,
        cost_seq = cost_seq, n_fold = 3, method = "mip")
      }
    Message <packageStartupMessage>
      Loading required package: gurobi
      Loading required package: slam
    Code
      predict(mdl1, new_data = df, type = "raw", layer = "bag")
    Output
      # A tibble: 80 x 1
         .pred
         <dbl>
       1 -1.00
       2 -1.00
       3 -1.00
       4 -1.00
       5  1.04
       6  1.04
       7  1.04
       8  1.04
       9 -1.13
      10 -1.13
      # ... with 70 more rows
    Code
      df %>% bind_cols(predict(mdl2, df, type = "class")) %>% bind_cols(predict(mdl2,
        df, type = "raw")) %>% distinct(bag_name, bag_label, .pred_class, .pred)
    Output
         bag_label bag_name .pred_class      .pred
      1          0     bag1           0 -0.5932349
      2          1     bag2           1  0.7493612
      3          0     bag3           0 -0.9387030
      4          1     bag4           1  1.2126533
      5          0     bag5           0 -0.8094506
      6          0     bag6           0 -0.8083522
      7          1     bag7           1  0.6587946
      8          0     bag8           0 -0.9032079
      9          1     bag9           1  0.5855234
      10         1    bag10           1  1.2019300
      11         1    bag11           1  1.2689043
      12         0    bag12           0 -0.8143970
      13         1    bag13           1  0.8591738
      14         1    bag14           1  1.0000000
      15         1    bag15           1  1.1078369
      16         1    bag16           1  1.2117319
      17         0    bag17           0 -0.6022075
      18         1    bag18           1  0.9355648
      19         0    bag19           0 -0.7314129
      20         1    bag20           1  1.0393764

# `generate_mild_df()` examples work

    Code
      set.seed(8)
      mild_data <- generate_mild_df(nbag = 7, ninst = 3, nsample = 20, ncov = 2,
        nimp_pos = 1, dist = rep("mvnormal", 3), mean = list(rep(5, 1), rep(15, 2), 0))
      library(dplyr)
      distinct(mild_data, bag_label, bag_name, instance_name)
    Output
         bag_label bag_name instance_name
      1          0     bag1     bag1inst1
      2          0     bag1     bag1inst2
      3          0     bag1     bag1inst3
      4          0     bag2     bag2inst1
      5          0     bag2     bag2inst2
      6          0     bag2     bag2inst3
      7          1     bag3     bag3inst1
      8          1     bag3     bag3inst2
      9          1     bag3     bag3inst3
      10         0     bag4     bag4inst1
      11         0     bag4     bag4inst2
      12         0     bag4     bag4inst3
      13         0     bag5     bag5inst1
      14         0     bag5     bag5inst2
      15         0     bag5     bag5inst3
      16         1     bag6     bag6inst1
      17         1     bag6     bag6inst2
      18         1     bag6     bag6inst3
      19         0     bag7     bag7inst1
      20         0     bag7     bag7inst2
      21         0     bag7     bag7inst3
    Code
      split(mild_data[, 4:5], mild_data$instance_name) %>% sapply(colMeans) %>% round(
        2) %>% t()
    Output
                   X1    X2
      bag1inst1 14.95 14.63
      bag1inst2 15.53 15.42
      bag1inst3 14.27 16.08
      bag2inst1 15.29 15.01
      bag2inst2 15.78 14.87
      bag2inst3 14.53 15.71
      bag3inst1 14.79 14.83
      bag3inst2  5.36 -0.69
      bag3inst3 15.13 15.78
      bag4inst1 15.32 14.46
      bag4inst2 15.31 15.53
      bag4inst3 15.93 14.55
      bag5inst1 15.25 14.25
      bag5inst2 14.98 16.03
      bag5inst3 15.48 14.95
      bag6inst1  4.83  0.26
      bag6inst2 16.23 16.06
      bag6inst3 15.31 14.56
      bag7inst1 14.74 14.90
      bag7inst2 14.61 15.03
      bag7inst3 15.17 15.20

# `kme()` examples work

    Code
      x = data.frame(instance_name = c("inst_1", "inst_2", "inst_1"), X1 = c(-0.4,
        0.5, 2))
      kme(x)
    Output
                [,1]      [,2]
      [1,] 0.8748808 0.9269533
      [2,] 0.9269533 1.0000000
    Code
      mild_df1 <- generate_mild_df(nbag = 10, positive_degree = 3)
      kme(mild_df1)
    Output
                 [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
       [1,] 0.4169122 0.3523994 0.2999620 0.3919451 0.2671537 0.3808291 0.3178319
       [2,] 0.3523994 0.4001522 0.3488563 0.3862459 0.3258604 0.3828253 0.3553224
       [3,] 0.2999620 0.3488563 0.3830298 0.3729092 0.3410245 0.3829949 0.3563669
       [4,] 0.3919451 0.3862459 0.3729092 0.6736729 0.3829977 0.4622801 0.3786055
       [5,] 0.2671537 0.3258604 0.3410245 0.3829977 0.3866819 0.3438624 0.3125532
       [6,] 0.3808291 0.3828253 0.3829949 0.4622801 0.3438624 0.5928032 0.3992530
       [7,] 0.3178319 0.3553224 0.3563669 0.3786055 0.3125532 0.3992530 0.4072973
       [8,] 0.2886348 0.3157459 0.2987742 0.3711378 0.2682204 0.3401411 0.2749737
       [9,] 0.3872634 0.4011600 0.3740848 0.4325844 0.3109014 0.4722626 0.3594980
      [10,] 0.3086363 0.3301951 0.2900993 0.3880930 0.2750935 0.3674942 0.3147702
      [11,] 0.3300471 0.3715490 0.3490256 0.3765055 0.3468922 0.3911776 0.3134912
      [12,] 0.3496296 0.3733415 0.3661626 0.5378319 0.3513647 0.4593275 0.3566796
      [13,] 0.2643695 0.3083248 0.3592159 0.3650698 0.3075189 0.3443388 0.3521353
      [14,] 0.3510899 0.3496693 0.3579273 0.4438735 0.3136538 0.4244626 0.3410867
      [15,] 0.3306274 0.3505787 0.3460770 0.4034540 0.3067107 0.4154028 0.3552658
      [16,] 0.3547158 0.3407101 0.3166309 0.3790609 0.2549436 0.3913973 0.3093184
      [17,] 0.3413221 0.3310640 0.3056185 0.4769570 0.2984654 0.3205515 0.3010842
      [18,] 0.3385712 0.3715150 0.3362378 0.3772033 0.3236153 0.3631170 0.3673017
      [19,] 0.3274643 0.3157874 0.3209078 0.3923291 0.2950952 0.3912085 0.3039875
      [20,] 0.3024896 0.3319636 0.3544274 0.3987057 0.3375483 0.4542176 0.3624589
      [21,] 0.3037886 0.3305133 0.3058440 0.4023323 0.2933122 0.3999505 0.3038551
      [22,] 0.4046782 0.4063992 0.3687206 0.4748479 0.3561605 0.5333569 0.3857608
      [23,] 0.2921442 0.3529623 0.2947198 0.3825395 0.2826722 0.3598854 0.2964741
      [24,] 0.3670381 0.3722187 0.3556825 0.4504677 0.3279440 0.4540149 0.3728457
      [25,] 0.3293533 0.3842095 0.3365811 0.3505797 0.3083936 0.3654656 0.3492568
      [26,] 0.4514919 0.4317108 0.3776675 0.5362912 0.3806510 0.4668916 0.3974679
      [27,] 0.3072870 0.3522197 0.3407901 0.4046125 0.3505049 0.3589900 0.3183809
      [28,] 0.3351851 0.3453512 0.3313021 0.4664949 0.3088645 0.4280774 0.3465275
      [29,] 0.4277095 0.3869842 0.3158980 0.4345843 0.2831570 0.3771593 0.3238047
      [30,] 0.3918940 0.4233512 0.3803228 0.5079662 0.3517907 0.4494309 0.3917467
      [31,] 0.3209992 0.3356011 0.3067535 0.3937972 0.2606738 0.3971114 0.3341408
      [32,] 0.3304344 0.3615479 0.3098770 0.3813640 0.3323581 0.3808892 0.3229543
      [33,] 0.3633943 0.3933628 0.4126571 0.4078071 0.3401322 0.4569400 0.3942821
      [34,] 0.3187196 0.3354348 0.3444837 0.4187835 0.3351518 0.3974189 0.3215929
      [35,] 0.3067201 0.3295164 0.3086434 0.4358080 0.2989232 0.3744900 0.3193445
      [36,] 0.3709173 0.3094088 0.2352705 0.3380354 0.2257843 0.3056635 0.2402585
      [37,] 0.3747756 0.3482068 0.3025652 0.4241205 0.2659261 0.4055969 0.3187351
      [38,] 0.3645088 0.3434428 0.3443278 0.3946202 0.2756704 0.4240096 0.3299400
      [39,] 0.3080024 0.3640326 0.3355290 0.3848462 0.2924023 0.3766813 0.3508378
      [40,] 0.4362794 0.4125146 0.3767652 0.4305746 0.3363838 0.4993309 0.3431162
                 [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
       [1,] 0.2886348 0.3872634 0.3086363 0.3300471 0.3496296 0.2643695 0.3510899
       [2,] 0.3157459 0.4011600 0.3301951 0.3715490 0.3733415 0.3083248 0.3496693
       [3,] 0.2987742 0.3740848 0.2900993 0.3490256 0.3661626 0.3592159 0.3579273
       [4,] 0.3711378 0.4325844 0.3880930 0.3765055 0.5378319 0.3650698 0.4438735
       [5,] 0.2682204 0.3109014 0.2750935 0.3468922 0.3513647 0.3075189 0.3136538
       [6,] 0.3401411 0.4722626 0.3674942 0.3911776 0.4593275 0.3443388 0.4244626
       [7,] 0.2749737 0.3594980 0.3147702 0.3134912 0.3566796 0.3521353 0.3410867
       [8,] 0.3827260 0.3907545 0.2988163 0.3308321 0.3751270 0.2927895 0.3424322
       [9,] 0.3907545 0.5245163 0.3503800 0.3956145 0.4558087 0.3169918 0.4143504
      [10,] 0.2988163 0.3503800 0.3778166 0.3133673 0.3854424 0.2845932 0.3253879
      [11,] 0.3308321 0.3956145 0.3133673 0.4192976 0.3827056 0.3105342 0.3439707
      [12,] 0.3751270 0.4558087 0.3854424 0.3827056 0.5381580 0.3410197 0.4040592
      [13,] 0.2927895 0.3169918 0.2845932 0.3105342 0.3410197 0.4152752 0.3384331
      [14,] 0.3424322 0.4143504 0.3253879 0.3439707 0.4040592 0.3384331 0.4227283
      [15,] 0.3529021 0.4052576 0.3318198 0.3378625 0.3899277 0.3435705 0.3792346
      [16,] 0.3247552 0.4200867 0.3237023 0.3466853 0.3903709 0.3004923 0.3533612
      [17,] 0.3023912 0.3428421 0.3114730 0.3110601 0.3819310 0.3000919 0.3629485
      [18,] 0.2923464 0.3394161 0.3164056 0.3531750 0.3375635 0.3346717 0.3247464
      [19,] 0.2713716 0.3836950 0.2482132 0.3223733 0.3761191 0.2686236 0.3305258
      [20,] 0.2857859 0.3744232 0.3174561 0.3395988 0.3984483 0.3315578 0.3550107
      [21,] 0.2627253 0.3836853 0.2795323 0.3301624 0.3831656 0.2488448 0.3148869
      [22,] 0.3406292 0.4621339 0.3923090 0.3955028 0.4495619 0.3141189 0.4283485
      [23,] 0.3157345 0.3856858 0.3494546 0.3538506 0.3917857 0.2697028 0.3082309
      [24,] 0.3275562 0.4251279 0.3382506 0.3577489 0.4262159 0.3256938 0.3830319
      [25,] 0.3231252 0.3904057 0.3485463 0.3771474 0.3788117 0.3159366 0.3161134
      [26,] 0.3373112 0.4363885 0.4001063 0.4178917 0.4635879 0.3431673 0.4212106
      [27,] 0.3388433 0.3562988 0.3225072 0.3660954 0.3718644 0.3297816 0.3608778
      [28,] 0.2935088 0.3908359 0.3247119 0.3233924 0.4104011 0.3010204 0.3750590
      [29,] 0.3255437 0.4056847 0.3709777 0.3798311 0.3901575 0.3028651 0.3793250
      [30,] 0.3773517 0.4505271 0.4349212 0.4046103 0.4724630 0.3729573 0.4305713
      [31,] 0.3151219 0.4048709 0.3019086 0.2964317 0.3670353 0.2776221 0.3516817
      [32,] 0.3101098 0.3605160 0.3237806 0.3617166 0.3625330 0.2743012 0.3224096
      [33,] 0.3271257 0.4471554 0.3090527 0.3839613 0.3851377 0.3774804 0.4184469
      [34,] 0.3434242 0.3851384 0.2983263 0.3592944 0.3967367 0.3314950 0.3647405
      [35,] 0.3355117 0.3918822 0.3211793 0.3102746 0.4325159 0.2788364 0.3399177
      [36,] 0.2370985 0.3357440 0.2703925 0.2874996 0.2988993 0.1794404 0.2905320
      [37,] 0.3102639 0.4125572 0.3560512 0.3232770 0.4074992 0.2703437 0.3675738
      [38,] 0.3191465 0.4189078 0.3061028 0.3536871 0.3836219 0.3285568 0.3830229
      [39,] 0.3091127 0.3884269 0.3297345 0.3310730 0.3640645 0.3208774 0.3476835
      [40,] 0.3742521 0.5217239 0.3386285 0.4284365 0.4327775 0.2919186 0.4346810
                [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]
       [1,] 0.3306274 0.3547158 0.3413221 0.3385712 0.3274643 0.3024896 0.3037886
       [2,] 0.3505787 0.3407101 0.3310640 0.3715150 0.3157874 0.3319636 0.3305133
       [3,] 0.3460770 0.3166309 0.3056185 0.3362378 0.3209078 0.3544274 0.3058440
       [4,] 0.4034540 0.3790609 0.4769570 0.3772033 0.3923291 0.3987057 0.4023323
       [5,] 0.3067107 0.2549436 0.2984654 0.3236153 0.2950952 0.3375483 0.2933122
       [6,] 0.4154028 0.3913973 0.3205515 0.3631170 0.3912085 0.4542176 0.3999505
       [7,] 0.3552658 0.3093184 0.3010842 0.3673017 0.3039875 0.3624589 0.3038551
       [8,] 0.3529021 0.3247552 0.3023912 0.2923464 0.2713716 0.2857859 0.2627253
       [9,] 0.4052576 0.4200867 0.3428421 0.3394161 0.3836950 0.3744232 0.3836853
      [10,] 0.3318198 0.3237023 0.3114730 0.3164056 0.2482132 0.3174561 0.2795323
      [11,] 0.3378625 0.3466853 0.3110601 0.3531750 0.3223733 0.3395988 0.3301624
      [12,] 0.3899277 0.3903709 0.3819310 0.3375635 0.3761191 0.3984483 0.3831656
      [13,] 0.3435705 0.3004923 0.3000919 0.3346717 0.2686236 0.3315578 0.2488448
      [14,] 0.3792346 0.3533612 0.3629485 0.3247464 0.3305258 0.3550107 0.3148869
      [15,] 0.4029821 0.3329319 0.3200534 0.3483374 0.3092085 0.3560920 0.2891205
      [16,] 0.3329319 0.4072145 0.3136260 0.3063168 0.3153526 0.3135427 0.3179032
      [17,] 0.3200534 0.3136260 0.4178473 0.3216383 0.2921914 0.2881410 0.2887689
      [18,] 0.3483374 0.3063168 0.3216383 0.4130369 0.2840406 0.3254596 0.2799843
      [19,] 0.3092085 0.3153526 0.2921914 0.2840406 0.3959299 0.3322660 0.3393178
      [20,] 0.3560920 0.3135427 0.2881410 0.3254596 0.3322660 0.4044005 0.3257537
      [21,] 0.2891205 0.3179032 0.2887689 0.2799843 0.3393178 0.3257537 0.4047794
      [22,] 0.4091661 0.3738722 0.3595939 0.3721547 0.3633162 0.4213864 0.3880263
      [23,] 0.3054019 0.3466469 0.3022233 0.3044542 0.2604175 0.2995181 0.3488779
      [24,] 0.3812947 0.3548821 0.3396105 0.3582028 0.3601843 0.3795341 0.3540605
      [25,] 0.3478419 0.3491553 0.2969050 0.3747642 0.2905926 0.3273992 0.3005663
      [26,] 0.3904225 0.3992663 0.4359671 0.4253176 0.3837960 0.3945064 0.3896817
      [27,] 0.3585833 0.3014212 0.3401771 0.3509750 0.2805411 0.3273872 0.2782515
      [28,] 0.3428719 0.3314276 0.3467582 0.3160977 0.3306523 0.3545179 0.3646012
      [29,] 0.3394214 0.4170320 0.3993973 0.3675633 0.3038418 0.3064804 0.3261697
      [30,] 0.4099238 0.4139901 0.4213449 0.3990849 0.3207753 0.3835597 0.3628194
      [31,] 0.3567115 0.3172887 0.3049912 0.3059889 0.3020181 0.3197710 0.3215577
      [32,] 0.3483399 0.2912989 0.3062592 0.3634603 0.2945235 0.3313570 0.2940884
      [33,] 0.3816499 0.3762535 0.3381053 0.3651828 0.3660556 0.3826280 0.3621237
      [34,] 0.3678903 0.3200297 0.3223298 0.3341906 0.3314275 0.3497056 0.2945803
      [35,] 0.3583229 0.3023115 0.3210037 0.3041208 0.3219870 0.3326105 0.3030481
      [36,] 0.2544942 0.3001889 0.3109006 0.2631206 0.2796083 0.2363907 0.2927193
      [37,] 0.3423002 0.3730642 0.3483797 0.3060860 0.3134191 0.3240729 0.3292184
      [38,] 0.3477659 0.3961409 0.3230067 0.3213942 0.3424865 0.3367813 0.3246403
      [39,] 0.3423561 0.3343108 0.3173556 0.3336023 0.2765495 0.3222561 0.3275091
      [40,] 0.3966873 0.4149241 0.3552640 0.3474666 0.4134704 0.3821023 0.3961611
                [,22]     [,23]     [,24]     [,25]     [,26]     [,27]     [,28]
       [1,] 0.4046782 0.2921442 0.3670381 0.3293533 0.4514919 0.3072870 0.3351851
       [2,] 0.4063992 0.3529623 0.3722187 0.3842095 0.4317108 0.3522197 0.3453512
       [3,] 0.3687206 0.2947198 0.3556825 0.3365811 0.3776675 0.3407901 0.3313021
       [4,] 0.4748479 0.3825395 0.4504677 0.3505797 0.5362912 0.4046125 0.4664949
       [5,] 0.3561605 0.2826722 0.3279440 0.3083936 0.3806510 0.3505049 0.3088645
       [6,] 0.5333569 0.3598854 0.4540149 0.3654656 0.4668916 0.3589900 0.4280774
       [7,] 0.3857608 0.2964741 0.3728457 0.3492568 0.3974679 0.3183809 0.3465275
       [8,] 0.3406292 0.3157345 0.3275562 0.3231252 0.3373112 0.3388433 0.2935088
       [9,] 0.4621339 0.3856858 0.4251279 0.3904057 0.4363885 0.3562988 0.3908359
      [10,] 0.3923090 0.3494546 0.3382506 0.3485463 0.4001063 0.3225072 0.3247119
      [11,] 0.3955028 0.3538506 0.3577489 0.3771474 0.4178917 0.3660954 0.3233924
      [12,] 0.4495619 0.3917857 0.4262159 0.3788117 0.4635879 0.3718644 0.4104011
      [13,] 0.3141189 0.2697028 0.3256938 0.3159366 0.3431673 0.3297816 0.3010204
      [14,] 0.4283485 0.3082309 0.3830319 0.3161134 0.4212106 0.3608778 0.3750590
      [15,] 0.4091661 0.3054019 0.3812947 0.3478419 0.3904225 0.3585833 0.3428719
      [16,] 0.3738722 0.3466469 0.3548821 0.3491553 0.3992663 0.3014212 0.3314276
      [17,] 0.3595939 0.3022233 0.3396105 0.2969050 0.4359671 0.3401771 0.3467582
      [18,] 0.3721547 0.3044542 0.3582028 0.3747642 0.4253176 0.3509750 0.3160977
      [19,] 0.3633162 0.2604175 0.3601843 0.2905926 0.3837960 0.2805411 0.3306523
      [20,] 0.4213864 0.2995181 0.3795341 0.3273992 0.3945064 0.3273872 0.3545179
      [21,] 0.3880263 0.3488779 0.3540605 0.3005663 0.3896817 0.2782515 0.3646012
      [22,] 0.5630475 0.3753065 0.4449969 0.3733252 0.5032117 0.3874373 0.4322735
      [23,] 0.3753065 0.4471016 0.3311823 0.3651890 0.3853135 0.3199225 0.3380487
      [24,] 0.4449969 0.3311823 0.4151443 0.3564034 0.4466317 0.3462490 0.3836512
      [25,] 0.3733252 0.3651890 0.3564034 0.4298102 0.4069444 0.3413267 0.3100067
      [26,] 0.5032117 0.3853135 0.4466317 0.4069444 0.5818781 0.4032938 0.4299712
      [27,] 0.3874373 0.3199225 0.3462490 0.3413267 0.4032938 0.3995114 0.3234780
      [28,] 0.4322735 0.3380487 0.3836512 0.3100067 0.4299712 0.3234780 0.4043163
      [29,] 0.4160148 0.3796291 0.3704163 0.3798308 0.5021081 0.3503216 0.3583275
      [30,] 0.4824457 0.4395676 0.4209159 0.4195498 0.5101399 0.4143516 0.4201927
      [31,] 0.3968881 0.3119012 0.3654678 0.3098126 0.3696027 0.3010211 0.3550438
      [32,] 0.4147757 0.3143400 0.3609095 0.3576175 0.4206899 0.3590449 0.3179471
      [33,] 0.4358190 0.3327537 0.4046812 0.3552375 0.4318491 0.3590810 0.3871017
      [34,] 0.3851446 0.2917805 0.3678323 0.3276997 0.3922857 0.3619419 0.3271772
      [35,] 0.3826448 0.3047897 0.3715418 0.3309257 0.3824156 0.3248125 0.3375729
      [36,] 0.3627135 0.2818273 0.3044356 0.2729893 0.4067361 0.2578816 0.2968476
      [37,] 0.4269345 0.3464054 0.3738811 0.3354771 0.4384104 0.3105591 0.3670421
      [38,] 0.3923521 0.3149255 0.3712310 0.3314089 0.4082615 0.3153282 0.3489113
      [39,] 0.3864728 0.3746239 0.3510428 0.3499524 0.3858336 0.3302087 0.3543242
      [40,] 0.5149685 0.3622524 0.4349479 0.3730711 0.4803461 0.3754398 0.3987842
                [,29]     [,30]     [,31]     [,32]     [,33]     [,34]     [,35]
       [1,] 0.4277095 0.3918940 0.3209992 0.3304344 0.3633943 0.3187196 0.3067201
       [2,] 0.3869842 0.4233512 0.3356011 0.3615479 0.3933628 0.3354348 0.3295164
       [3,] 0.3158980 0.3803228 0.3067535 0.3098770 0.4126571 0.3444837 0.3086434
       [4,] 0.4345843 0.5079662 0.3937972 0.3813640 0.4078071 0.4187835 0.4358080
       [5,] 0.2831570 0.3517907 0.2606738 0.3323581 0.3401322 0.3351518 0.2989232
       [6,] 0.3771593 0.4494309 0.3971114 0.3808892 0.4569400 0.3974189 0.3744900
       [7,] 0.3238047 0.3917467 0.3341408 0.3229543 0.3942821 0.3215929 0.3193445
       [8,] 0.3255437 0.3773517 0.3151219 0.3101098 0.3271257 0.3434242 0.3355117
       [9,] 0.4056847 0.4505271 0.4048709 0.3605160 0.4471554 0.3851384 0.3918822
      [10,] 0.3709777 0.4349212 0.3019086 0.3237806 0.3090527 0.2983263 0.3211793
      [11,] 0.3798311 0.4046103 0.2964317 0.3617166 0.3839613 0.3592944 0.3102746
      [12,] 0.3901575 0.4724630 0.3670353 0.3625330 0.3851377 0.3967367 0.4325159
      [13,] 0.3028651 0.3729573 0.2776221 0.2743012 0.3774804 0.3314950 0.2788364
      [14,] 0.3793250 0.4305713 0.3516817 0.3224096 0.4184469 0.3647405 0.3399177
      [15,] 0.3394214 0.4099238 0.3567115 0.3483399 0.3816499 0.3678903 0.3583229
      [16,] 0.4170320 0.4139901 0.3172887 0.2912989 0.3762535 0.3200297 0.3023115
      [17,] 0.3993973 0.4213449 0.3049912 0.3062592 0.3381053 0.3223298 0.3210037
      [18,] 0.3675633 0.3990849 0.3059889 0.3634603 0.3651828 0.3341906 0.3041208
      [19,] 0.3038418 0.3207753 0.3020181 0.2945235 0.3660556 0.3314275 0.3219870
      [20,] 0.3064804 0.3835597 0.3197710 0.3313570 0.3826280 0.3497056 0.3326105
      [21,] 0.3261697 0.3628194 0.3215577 0.2940884 0.3621237 0.2945803 0.3030481
      [22,] 0.4160148 0.4824457 0.3968881 0.4147757 0.4358190 0.3851446 0.3826448
      [23,] 0.3796291 0.4395676 0.3119012 0.3143400 0.3327537 0.2917805 0.3047897
      [24,] 0.3704163 0.4209159 0.3654678 0.3609095 0.4046812 0.3678323 0.3715418
      [25,] 0.3798308 0.4195498 0.3098126 0.3576175 0.3552375 0.3276997 0.3309257
      [26,] 0.5021081 0.5101399 0.3696027 0.4206899 0.4318491 0.3922857 0.3824156
      [27,] 0.3503216 0.4143516 0.3010211 0.3590449 0.3590810 0.3619419 0.3248125
      [28,] 0.3583275 0.4201927 0.3550438 0.3179471 0.3871017 0.3271772 0.3375729
      [29,] 0.5562114 0.4896433 0.3201169 0.3412564 0.3858215 0.3268655 0.2998863
      [30,] 0.4896433 0.5604001 0.3818702 0.3887106 0.4317382 0.3790934 0.3781906
      [31,] 0.3201169 0.3818702 0.3813176 0.3107423 0.3666519 0.3145105 0.3413322
      [32,] 0.3412564 0.3887106 0.3107423 0.4028639 0.3279293 0.3447714 0.3375131
      [33,] 0.3858215 0.4317382 0.3666519 0.3279293 0.5115058 0.3683147 0.3183061
      [34,] 0.3268655 0.3790934 0.3145105 0.3447714 0.3683147 0.3886675 0.3474166
      [35,] 0.2998863 0.3781906 0.3413322 0.3375131 0.3183061 0.3474166 0.4157505
      [36,] 0.3992034 0.3401047 0.2711894 0.2902113 0.2902643 0.2515062 0.2591211
      [37,] 0.4197093 0.4377885 0.3444593 0.3202151 0.3562870 0.3131996 0.3377408
      [38,] 0.4048258 0.4059210 0.3258159 0.2927319 0.4211501 0.3429983 0.2983918
      [39,] 0.3608347 0.4316374 0.3462349 0.3132448 0.3930252 0.3068435 0.3068626
      [40,] 0.4386672 0.4426953 0.3904327 0.3934714 0.4677351 0.4012890 0.3686771
                [,36]     [,37]     [,38]     [,39]     [,40]
       [1,] 0.3709173 0.3747756 0.3645088 0.3080024 0.4362794
       [2,] 0.3094088 0.3482068 0.3434428 0.3640326 0.4125146
       [3,] 0.2352705 0.3025652 0.3443278 0.3355290 0.3767652
       [4,] 0.3380354 0.4241205 0.3946202 0.3848462 0.4305746
       [5,] 0.2257843 0.2659261 0.2756704 0.2924023 0.3363838
       [6,] 0.3056635 0.4055969 0.4240096 0.3766813 0.4993309
       [7,] 0.2402585 0.3187351 0.3299400 0.3508378 0.3431162
       [8,] 0.2370985 0.3102639 0.3191465 0.3091127 0.3742521
       [9,] 0.3357440 0.4125572 0.4189078 0.3884269 0.5217239
      [10,] 0.2703925 0.3560512 0.3061028 0.3297345 0.3386285
      [11,] 0.2874996 0.3232770 0.3536871 0.3310730 0.4284365
      [12,] 0.2988993 0.4074992 0.3836219 0.3640645 0.4327775
      [13,] 0.1794404 0.2703437 0.3285568 0.3208774 0.2919186
      [14,] 0.2905320 0.3675738 0.3830229 0.3476835 0.4346810
      [15,] 0.2544942 0.3423002 0.3477659 0.3423561 0.3966873
      [16,] 0.3001889 0.3730642 0.3961409 0.3343108 0.4149241
      [17,] 0.3109006 0.3483797 0.3230067 0.3173556 0.3552640
      [18,] 0.2631206 0.3060860 0.3213942 0.3336023 0.3474666
      [19,] 0.2796083 0.3134191 0.3424865 0.2765495 0.4134704
      [20,] 0.2363907 0.3240729 0.3367813 0.3222561 0.3821023
      [21,] 0.2927193 0.3292184 0.3246403 0.3275091 0.3961611
      [22,] 0.3627135 0.4269345 0.3923521 0.3864728 0.5149685
      [23,] 0.2818273 0.3464054 0.3149255 0.3746239 0.3622524
      [24,] 0.3044356 0.3738811 0.3712310 0.3510428 0.4349479
      [25,] 0.2729893 0.3354771 0.3314089 0.3499524 0.3730711
      [26,] 0.4067361 0.4384104 0.4082615 0.3858336 0.4803461
      [27,] 0.2578816 0.3105591 0.3153282 0.3302087 0.3754398
      [28,] 0.2968476 0.3670421 0.3489113 0.3543242 0.3987842
      [29,] 0.3992034 0.4197093 0.4048258 0.3608347 0.4386672
      [30,] 0.3401047 0.4377885 0.4059210 0.4316374 0.4426953
      [31,] 0.2711894 0.3444593 0.3258159 0.3462349 0.3904327
      [32,] 0.2902113 0.3202151 0.2927319 0.3132448 0.3934714
      [33,] 0.2902643 0.3562870 0.4211501 0.3930252 0.4677351
      [34,] 0.2515062 0.3131996 0.3429983 0.3068435 0.4012890
      [35,] 0.2591211 0.3377408 0.2983918 0.3068626 0.3686771
      [36,] 0.4220373 0.3496548 0.2905701 0.2660560 0.4066057
      [37,] 0.3496548 0.4139086 0.3615792 0.3398438 0.4231177
      [38,] 0.2905701 0.3615792 0.4243788 0.3349206 0.4348109
      [39,] 0.2660560 0.3398438 0.3349206 0.3967751 0.3664759
      [40,] 0.4066057 0.4231177 0.4348109 0.3664759 0.6118455

# `mi()` examples work

    Code
      mil_data <- generate_mild_df(positive_degree = 3, nbag = 10)
      with(mil_data, head(mi(bag_label, bag_name)))
    Output
           bag_label bag_name
      [1,] "1"       "bag1"  
      [2,] "1"       "bag1"  
      [3,] "1"       "bag1"  
      [4,] "1"       "bag1"  
      [5,] "1"       "bag1"  
      [6,] "1"       "bag1"  
    Code
      df <- get_all_vars(mi(bag_label, bag_name) ~ X1 + X2, data = mil_data)
      head(df)
    Output
        bag_label bag_name         X1         X2
      1         1     bag1 -0.4464099  1.1019817
      2         1     bag1  1.2311306 -0.8395224
      3         1     bag1  0.9309844  2.2884239
      4         1     bag1  2.0311929  2.1704369
      5         1     bag1  0.5209816 -1.1255467
      6         1     bag1 -0.4920105  2.4251912

# `mild_df()` examples work

    Code
      mild_df(bag_label = factor(c(1, 1, 0)), bag_name = c(rep("bag_1", 2), "bag_2"),
      instance_name = c("bag_1_inst_1", "bag_1_inst_2", "bag_2_inst_1"), X1 = c(-0.4,
        0.5, 2), instance_label = c(0, 1, 0))
    Output
        bag_label bag_name instance_name   X1
      1         1    bag_1  bag_1_inst_1 -0.4
      2         1    bag_1  bag_1_inst_2  0.5
      3         0    bag_2  bag_2_inst_1  2.0

# `mild()` examples work

    Code
      mil_data <- generate_mild_df(positive_degree = 3, nbag = 10)
      with(mil_data, head(mild(bag_label, bag_name, instance_name)))
    Output
           bag_label bag_name instance_name
      [1,] "1"       "bag1"   "bag1inst1"  
      [2,] "1"       "bag1"   "bag1inst1"  
      [3,] "1"       "bag1"   "bag1inst1"  
      [4,] "1"       "bag1"   "bag1inst1"  
      [5,] "1"       "bag1"   "bag1inst1"  
      [6,] "1"       "bag1"   "bag1inst1"  
    Code
      df <- get_all_vars(mild(bag_label, bag_name) ~ X1 + X2, data = mil_data)
      head(df)
    Output
        bag_label bag_name          X1         X2
      1         1     bag1  0.36529504 -0.3713889
      2         1     bag1  0.07733708 -0.5885037
      3         1     bag1 -1.59611098  0.3456669
      4         1     bag1 -0.16911543  1.4814259
      5         1     bag1 -0.85251086 -2.6362243
      6         1     bag1  1.40033082 -1.1679564

# `mior()` examples work

    Code
      set.seed(8)
      n <- 15
      X <- rbind(mvtnorm::rmvnorm(n / 3, mean = c(4, -2, 0)), mvtnorm::rmvnorm(n / 3,
      mean = c(0, 0, 0)), mvtnorm::rmvnorm(n / 3, mean = c(-2, 1, 0)))
      score <- X %*% c(2, -1, 0)
      y <- as.numeric(cut(score, c(-Inf, quantile(score, probs = 1:2 / 3), Inf)))
      bags <- seq_along(y)
      X <- rbind(X, mvtnorm::rmvnorm(n, mean = c(6, -3, 0)), mvtnorm::rmvnorm(n,
        mean = c(-6, 3, 0)))
      y <- c(y, rep(-1, 2 * n))
      bags <- rep(bags, 3)
      repr <- c(rep(1, n), rep(0, 2 * n))
      y_bag <- classify_bags(y, bags, condense = FALSE)
      mdl1 <- mior(X, y_bag, bags)
    Message <message>
      [Step 1] The optimization solution suggests that two intercepts are equal: b[1] == b[2].
      [Step 1] The optimization solution suggests that two intercepts are equal: b[2] == b[3].
    Warning <warning>
      [Step 1] There were NA values in `b`.  Replacing with 0.
    Message <message>
      [Step 2] The optimization solution suggests that two intercepts are equal: b[1] == b[2].
      [Step 2] The optimization solution suggests that two intercepts are equal: b[2] == b[3].
    Warning <warning>
      [Step 2] There were NA values in `b`.  Replacing with 0.
    Message <message>
      [Step 3] The optimization solution suggests that two intercepts are equal: b[2] == b[3].
    Warning <warning>
      [Step 3] There were NA values in `b`.  Replacing with 0.
    Code
      predict(mdl1, X, new_bags = bags)
    Output
      # A tibble: 45 x 1
         .pred_class
         <fct>      
       1 3          
       2 3          
       3 1          
       4 3          
       5 1          
       6 1          
       7 3          
       8 3          
       9 3          
      10 1          
      # ... with 35 more rows
    Code
      df1 <- bind_cols(y = y_bag, bags = bags, as.data.frame(X))
      df1 %>% bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %>%
        bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %>% distinct(y,
        bags, .pred_class, .pred)
    Output
         y bags .pred_class       .pred
      1  3    1           3  0.90124158
      2  3    2           3  1.04883866
      3  3    3           1 -0.49073166
      4  3    4           3  1.61050422
      5  3    5           1 -2.15203379
      6  1    6           1 -0.69258966
      7  2    7           3  1.14459624
      8  2    8           3  0.09219952
      9  2    9           3 -0.06936906
      10 2   10           1 -1.01712520
      11 1   11           1 -1.58425706
      12 1   12           1 -0.85540376
      13 2   13           1 -0.39651685
      14 1   14           1 -1.08037692
      15 1   15           3 -0.17273959

# `mismm()` example works

    Code
      set.seed(8)
      mil_data <- generate_mild_df(nbag = 15, nsample = 20, positive_prob = 0.15,
        sd_of_mean = rep(0.1, 3))
      mdl1 <- mismm(mil_data)
      mdl2 <- mismm(mild(bag_label, bag_name, instance_name) ~ X1 + X2 + X3, data = mil_data)
      if (require(gurobi)) {
        mdl3 <- mismm(mil_data, method = "mip", control = list(nystrom_args = list(m = 10,
          r = 10)))
        predict(mdl3, mil_data)
      }
    Output
      # A tibble: 1,200 x 1
         .pred_class
         <fct>      
       1 0          
       2 0          
       3 0          
       4 0          
       5 0          
       6 0          
       7 0          
       8 0          
       9 0          
      10 0          
      # ... with 1,190 more rows
    Code
      predict(mdl1, new_data = mil_data, type = "raw", layer = "bag")
    Output
      # A tibble: 1,200 x 1
          .pred
          <dbl>
       1 -0.289
       2 -0.289
       3 -0.289
       4 -0.289
       5 -0.289
       6 -0.289
       7 -0.289
       8 -0.289
       9 -0.289
      10 -0.289
      # ... with 1,190 more rows
    Code
      mil_data %>% bind_cols(predict(mdl2, mil_data, type = "class")) %>% bind_cols(
        predict(mdl2, mil_data, type = "raw")) %>% distinct(bag_name, bag_label,
        .pred_class, .pred)
    Output
         bag_label bag_name .pred_class       .pred
      1          0     bag1           0 -0.11956070
      2          1     bag2           1  0.21090014
      3          0     bag3           0 -0.09390996
      4          1     bag4           1  0.09450872
      5          0     bag5           0 -0.09219624
      6          0     bag6           0 -0.13385229
      7          1     bag7           1  0.15464759
      8          0     bag8           0 -0.04083047
      9          1     bag9           1  0.16941904
      10         1    bag10           1  0.25006646
      11         1    bag11           1  0.13690982
      12         0    bag12           0 -0.05835921
      13         1    bag13           1  0.17325203
      14         1    bag14           1  0.14325177
      15         1    bag15           1  0.32877489

# `predict.mismm()` examples work

    Code
      mil_data <- generate_mild_df(nbag = 15, nsample = 20, positive_prob = 0.15,
        sd_of_mean = rep(0.1, 3))
      mdl1 <- mismm(mil_data, control = list(sigma = 1 / 5))
      mil_data %>% bind_cols(predict(mdl1, mil_data, type = "class")) %>% bind_cols(
        predict(mdl1, mil_data, type = "raw")) %>% distinct(bag_name, bag_label,
        .pred_class, .pred)
    Output
         bag_label bag_name .pred_class       .pred
      1          0     bag1           0 -0.37740255
      2          1     bag2           1  0.28344679
      3          0     bag3           0 -0.33199064
      4          1     bag4           1  0.13194961
      5          0     bag5           0 -0.33495785
      6          0     bag6           0 -0.24794687
      7          1     bag7           1  0.26145917
      8          0     bag8           0 -0.06040958
      9          1     bag9           1  0.37934673
      10         1    bag10           1  0.39238521
      11         1    bag11           1  0.30107408
      12         0    bag12           0 -0.28196329
      13         1    bag13           1  0.32638769
      14         1    bag14           1  0.22273935
      15         1    bag15           1  0.45906821
    Code
      mil_data %>% bind_cols(predict(mdl1, mil_data, type = "class", layer = "instance")) %>%
        bind_cols(predict(mdl1, mil_data, type = "raw", layer = "instance")) %>%
        distinct(bag_name, instance_name, bag_label, .pred_class, .pred)
    Output
         bag_label bag_name instance_name .pred_class       .pred
      1          0     bag1     bag1inst1           0 -0.38021259
      2          0     bag1     bag1inst2           0 -0.42078066
      3          0     bag1     bag1inst3           0 -0.37740255
      4          0     bag1     bag1inst4           0 -0.42800397
      5          1     bag2     bag2inst1           0 -0.32139888
      6          1     bag2     bag2inst2           0 -0.36278924
      7          1     bag2     bag2inst3           0 -0.25074180
      8          1     bag2     bag2inst4           1  0.28344679
      9          0     bag3     bag3inst1           0 -0.33199064
      10         0     bag3     bag3inst2           0 -0.39525382
      11         0     bag3     bag3inst3           0 -0.34569461
      12         0     bag3     bag3inst4           0 -0.33304887
      13         1     bag4     bag4inst1           0 -0.31900998
      14         1     bag4     bag4inst2           0 -0.24545506
      15         1     bag4     bag4inst3           0 -0.22103767
      16         1     bag4     bag4inst4           1  0.13194961
      17         0     bag5     bag5inst1           0 -0.45906816
      18         0     bag5     bag5inst2           0 -0.44501101
      19         0     bag5     bag5inst3           0 -0.33495785
      20         0     bag5     bag5inst4           0 -0.40857446
      21         0     bag6     bag6inst1           0 -0.39161068
      22         0     bag6     bag6inst2           0 -0.30728351
      23         0     bag6     bag6inst3           0 -0.24794687
      24         0     bag6     bag6inst4           0 -0.40984793
      25         1     bag7     bag7inst1           0 -0.22847389
      26         1     bag7     bag7inst2           1  0.26145917
      27         1     bag7     bag7inst3           0 -0.31135055
      28         1     bag7     bag7inst4           0 -0.26689426
      29         0     bag8     bag8inst1           0 -0.06040958
      30         0     bag8     bag8inst2           0 -0.31502077
      31         0     bag8     bag8inst3           0 -0.43158096
      32         0     bag8     bag8inst4           0 -0.32769429
      33         1     bag9     bag9inst1           1  0.37934673
      34         1     bag9     bag9inst2           0 -0.25656688
      35         1     bag9     bag9inst3           0 -0.15597718
      36         1     bag9     bag9inst4           0 -0.31327836
      37         1    bag10    bag10inst1           1  0.39238521
      38         1    bag10    bag10inst2           1  0.37351991
      39         1    bag10    bag10inst3           0 -0.22796150
      40         1    bag10    bag10inst4           0 -0.30594715
      41         1    bag11    bag11inst1           1  0.30107408
      42         1    bag11    bag11inst2           0 -0.25283830
      43         1    bag11    bag11inst3           0 -0.31290676
      44         1    bag11    bag11inst4           1  0.10095951
      45         0    bag12    bag12inst1           0 -0.39928055
      46         0    bag12    bag12inst2           0 -0.34958706
      47         0    bag12    bag12inst3           0 -0.28196329
      48         0    bag12    bag12inst4           0 -0.35179512
      49         1    bag13    bag13inst1           1  0.32638769
      50         1    bag13    bag13inst2           0 -0.25396081
      51         1    bag13    bag13inst3           0 -0.41066831
      52         1    bag13    bag13inst4           0 -0.36702806
      53         1    bag14    bag14inst1           0 -0.27036333
      54         1    bag14    bag14inst2           0 -0.33179443
      55         1    bag14    bag14inst3           1  0.22273935
      56         1    bag14    bag14inst4           0 -0.34223518
      57         1    bag15    bag15inst1           0 -0.30562584
      58         1    bag15    bag15inst2           0 -0.23537016
      59         1    bag15    bag15inst3           0 -0.21896721
      60         1    bag15    bag15inst4           1  0.45906821

# `misvm_orova()` examples work

    Code
      data("ordmvnorm")
      x <- ordmvnorm[, 4:8]
      y <- ordmvnorm$inst_label
      bags <- ordmvnorm$bag_name
      mdl1 <- misvm_orova(x, y, bags)
      predict(mdl1, x, new_bags = bags)
    Output
      # A tibble: 1,000 x 1
         .pred_class
         <fct>      
       1 2          
       2 2          
       3 2          
       4 2          
       5 2          
       6 4          
       7 4          
       8 4          
       9 4          
      10 4          
      # ... with 990 more rows
    Code
      df1 <- bind_cols(y = y, bags = bags, as.data.frame(x))
      df1 %>% bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %>%
        bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %>% select(
        -starts_with("V")) %>% distinct()
    Output
          y bags .pred_class     .pred_1     .pred_2      .pred_3      .pred_4
      1   2    1           2 -0.49320956  1.67420625  0.403627139 -1.482535104
      2   4    2           4 -5.22072993 -0.31539112 -0.286739380  1.047139157
      3   1    3           2  1.23515111  2.11455860  0.248735723 -2.658314597
      4   3    4           3 -1.72832706  0.75062925  1.854687998 -0.617696481
      5   1    5           1  2.43072851  1.77413174 -1.268827163 -3.027888470
      6   5    6           4 -6.72029215 -1.96838309  0.523407259  2.877017782
      7   4    7           4 -5.14248884 -0.98486731 -0.170088814  1.632895984
      8   4    8           3 -4.39294501 -0.19226360  2.468125852  1.693162221
      9   3    9           3 -3.09035944 -0.29490481  1.221649925 -0.734773122
      10  4   10           4 -5.22264829 -0.72179566  0.962347931  1.133161540
      11  5   11           4 -6.88488346 -1.68787409  0.606835683  2.489605539
      12  3   12           3 -2.52698791  0.02911339  1.200445200 -0.056400380
      13  5   13           4 -6.20000927 -2.99359870  1.526253180  2.144189529
      14  3   14           3 -2.61306805 -1.65090762  2.794964142 -0.687658008
      15  2   15           2  0.53879041  3.11051651  0.599602716 -1.238899308
      16  3   16           2 -2.23964633  0.80307449  0.674281026  0.141456042
      17  2   17           2 -0.14448700  1.78965294  0.986405687 -2.484022313
      18  2   18           2 -0.39667382  0.35231576  0.014722219 -1.608101444
      19  2   19           3  0.26535918  0.55126359  1.667599421 -1.562338164
      20  1   20           3  1.23043536  0.75145924  2.998430685 -2.250463394
      21  3   21           2 -3.40937666  0.97178133  0.770626270  0.044282019
      22  2   22           2 -1.11677628  0.87656632 -0.673858025 -1.600324921
      23  3   23           3 -1.58132292 -0.85125077  1.295848254 -0.786427204
      24  4   24           3 -5.01795386 -1.81611238  1.762495658  1.033792130
      25  2   25           2 -0.82293445  1.00008458  0.300230764 -1.491725518
      26  4   26           3 -5.56190034 -2.10507187  2.775335434  1.108809982
      27  4   27           4 -5.61869336 -0.55285728  1.175570112  1.251408169
      28  2   28           2 -0.68733258  1.04808967  0.681563702 -2.070746253
      29  5   29           4 -6.84305489 -1.59938354  0.500259561  2.891021996
      30  3   30           2 -2.46934927  0.30843434  0.138324749  0.269541541
      31  2   31           2 -1.67486748  1.97287475  0.941433043 -1.456244563
      32  5   32           3 -6.19856215 -1.44008281  2.273032873  1.637420446
      33  2   33           2  0.80449014  0.96920421  0.097811050 -1.837176696
      34  5   34           4 -5.93864773 -1.71153069  1.507060864  2.243188677
      35  4   35           4 -3.54030070 -1.26454786  0.218294816  0.825214570
      36  3   36           3 -2.91091739 -0.01813801  1.040181462 -0.244654035
      37  4   37           3 -4.34028057 -0.33578220  1.703792763  1.157735596
      38  2   38           3 -0.29785234  0.79213910  0.811687600 -1.309659626
      39  4   39           4 -3.93289475 -0.25491196 -0.098939703  0.751058182
      40  2   40           2  0.74546760  1.82938401  1.799332011 -1.193841193
      41  1   41           1  1.72081643  1.60283322  0.141948293 -2.974274127
      42  1   42           1  1.61788333  0.31375173 -1.133094729 -3.574170640
      43  2   43           2 -0.95291035  1.86694956  0.507711142 -1.870261176
      44  2   44           2 -0.08594647  2.49765155  0.818399655 -2.281022516
      45  2   45           2 -0.80066686  3.46539980  0.070848435 -1.511227599
      46  3   46           3 -3.71009647 -0.39476754  2.954191643  0.748543371
      47  3   47           3 -3.87319861  0.37147530  3.027487734 -0.410335775
      48  4   48           3 -5.91039238 -2.22469449  1.288490297  1.077528523
      49  2   49           2 -1.16079756  1.10886954 -0.364898062 -1.522456875
      50  4   50           3 -4.81825118 -1.07176495  2.779496872  0.684281654
      51  3   51           2 -2.08845994  0.66497086 -0.330669803  0.320171284
      52  5   52           4 -7.03433159  0.63296451  1.237563972  3.163450783
      53  5   53           4 -6.81105935 -1.50543964  1.570964272  2.567634516
      54  2   54           2 -1.12711690  1.50249006  0.983129892 -1.057531303
      55  4   55           4 -4.51904777 -0.73667418  0.206090764  0.999848967
      56  3   56           3 -2.87509064  0.23279124  0.298878310 -0.961693523
      57  5   57           4 -6.01293037 -2.41593210  1.413942739  2.422184470
      58  1   58           2  1.33443569  1.91464841 -0.588869973 -2.929469839
      59  2   59           2  0.03308947  1.68104728  0.341834922 -1.935615341
      60  4   60           4 -5.03505594  0.01663955  0.632029784  1.692072084
      61  2   61           2 -0.99415781  1.10264303 -1.229873931 -1.638300397
      62  2   62           2 -0.84947292  0.43166456 -0.071123548 -1.847015460
      63  2   63           2 -0.37837475  0.45683044 -0.154082963 -1.296894188
      64  5   64           4 -5.70697454 -2.54584380  1.562340568  3.079018355
      65  2   65           2 -0.08292151  2.54460452  0.812252028 -1.344516792
      66  4   66           4 -4.75519327 -0.61582595 -0.243473041  0.869436420
      67  2   67           2 -0.36710762  1.73773562  1.149568902 -2.021974982
      68  4   68           4 -5.01157902 -0.91995620  0.682765793  1.559799433
      69  1   69           2  1.67656036  2.65811075 -1.306778292 -2.967088425
      70  2   70           2 -0.04045096  1.51436864 -0.391681136 -1.548150703
      71  4   71           3 -5.23807227 -1.00050176  3.069307647  2.027173436
      72  4   72           3 -4.53830668 -0.85794012  1.151187873  1.133727952
      73  1   73           2  1.92137945  2.10662061  0.437543191 -3.301178036
      74  5   74           4 -6.50312221 -2.08668043 -0.027060421  2.650593518
      75  5   75           4 -7.38286819 -2.29358521 -0.721712628  2.798185435
      76  4   76           4 -5.34871381  0.27905957 -1.098959282  1.633430807
      77  1   77           2  1.43791326  2.87098301  0.562558120 -3.130787840
      78  3   78           3 -1.74922611  0.56541750  1.014440822  0.362360551
      79  2   79           3 -0.99959762  0.23099646  1.759615826 -1.563549385
      80  1   80           2  1.54042027  2.33147467 -1.696495617 -3.014575452
      81  3   81           2 -2.82311985  1.04832804  0.999694779 -0.519321873
      82  3   82           3 -2.28943402  0.02891798  0.983913133 -0.354596768
      83  2   83           2 -0.23771143  3.01822820  2.188263185 -1.981514638
      84  5   84           4 -6.83779728 -3.05807074  0.320623568  2.852712705
      85  2   85           2  0.35197209  1.59577057  1.428445929 -1.741704320
      86  2   86           3 -0.03449759  1.08353846  1.108915903 -1.885460723
      87  3   87           4 -1.85764475 -0.18750364 -1.093072365 -0.144602597
      88  3   88           2 -2.34691033  0.57388390  0.376616189 -0.778983613
      89  3   89           3 -1.86921300 -1.81239671  0.935926227 -0.154356483
      90  2   90           3  0.75015711  0.94191761  1.863590695 -1.837713287
      91  3   91           3 -2.82427523 -0.34997357  1.078720517  0.337152228
      92  4   92           3 -4.85152141 -1.46836603  1.742701219  1.549791926
      93  3   93           3 -3.18782378 -1.34717470  2.464902140 -0.194400131
      94  2   94           2 -0.31545870  1.82398926  1.027820789 -0.902978789
      95  3   95           3 -1.47673246 -0.19141948 -0.100882311 -0.469432868
      96  3   96           3 -1.77743702  0.90425519  0.969793679 -0.859564154
      97  2   97           2 -0.71999260  0.98970003 -0.280230519 -1.500981479
      98  2   98           2 -0.37022819  2.71604802 -0.173544201 -2.098886831
      99  2   99           3 -0.15606524  1.23213384  1.816353273 -1.386620141
      100 2  100           3 -0.61374607 -0.18478539  0.001745818 -1.525764751
      101 2  101           3 -0.22215890  0.78797969  0.830639653 -1.832256812
      102 2  102           3 -1.08026497 -0.12959372 -0.100344087 -1.578225251
      103 2  103           2 -1.46745442  1.11836961  0.289923905 -1.932967339
      104 5  104           4 -6.74143682 -1.36954632  1.744196836  2.855927183
      105 1  105           2  1.29328519  2.17836124 -0.493391405 -3.700607122
      106 3  106           3 -2.80290514  0.66231178  3.159278095  0.232456626
      107 3  107           3 -3.08646986 -1.48112685  1.000610176 -0.179058019
      108 1  108           2  1.18881663  2.87900563  2.010291138 -3.166709339
      109 3  109           3 -2.46471063  0.16359460  0.997784139 -0.461217908
      110 5  110           3 -6.62015382 -2.03014488  2.447184719  2.231667043
      111 1  111           1  2.68833715  1.63038692  0.631715601 -2.593557634
      112 3  112           3 -3.26172093 -0.04159985  0.977547058  0.092451320
      113 2  113           3 -1.31153742 -0.36494956 -0.081551791 -1.015454083
      114 1  114           1  2.45567048  2.43997829  0.539892253 -3.000861407
      115 5  115           4 -7.21898410 -1.74101356  1.237421942  3.212844735
      116 2  116           2 -0.46043458  1.50480481  0.787207983 -1.966381843
      117 4  117           4 -4.12207499 -0.99993559  0.487650192  1.664629318
      118 2  118           2  0.10153352  4.81239397 -0.367228077 -1.996762796
      119 1  119           2  1.20301527  2.17202168  0.890364706 -3.276670226
      120 5  120           4 -7.77072863 -1.96645841  1.380008811  3.267264321
      121 1  121           2  1.95928718  2.60208439  0.407048139 -3.112546177
      122 2  122           2 -0.39204781  2.70725080  1.028305440 -1.908803800
      123 3  123           3 -0.56144220 -1.04508665  1.225163891 -0.063953735
      124 3  124           3 -1.83868135  0.41038104  2.264208500 -0.411197838
      125 2  125           2 -0.59080008  2.65741267  2.271456356 -1.386655482
      126 2  126           3 -1.79623253  0.52405547  0.977201256 -1.275903250
      127 5  127           4 -7.19313413 -2.07433266 -0.613027778  2.322121152
      128 3  128           3 -3.02485112 -0.04996594  0.999803884  0.394895080
      129 1  129           2  2.09976324  3.48238393  0.995245533 -2.657817414
      130 3  130           2 -1.25906607  1.56438328  1.092990557 -0.282566297
      131 4  131           3 -5.56425757 -2.53091758  3.961450678  1.105272370
      132 2  132           2 -0.81782222  1.11525719  0.207620429 -1.494436508
      133 3  133           3 -3.08097719 -0.28302174  0.699224937 -0.009417545
      134 5  134           4 -6.64627922 -1.64958319  1.363528062  1.741930459
      135 4  135           4 -4.64751488  0.87958053  1.041544992  1.101565716
      136 5  136           4 -5.45143944 -2.09768514  1.169326063  2.867770787
      137 2  137           2 -0.93138510  1.81150107 -1.386732367 -1.849695150
      138 5  138           4 -6.76764449 -2.09482855  1.818138595  2.339770765
      139 5  139           3 -7.05809845 -1.71541762  2.686813232  2.287835168
      140 3  140           3 -3.20210194 -0.87408614  0.462418968 -0.507810340
      141 2  141           2  0.08373616  1.53573779 -0.598265697 -1.678449349
      142 3  142           3 -2.60828835  0.17736472  1.097359514 -0.149080929
      143 3  143           3 -3.20125908 -0.40694043  1.144984396 -0.284183352
      144 5  144           4 -8.01165644 -1.64704451  1.352610271  3.039300752
      145 4  145           4 -4.17182527 -1.14661611 -0.204827416  0.478856882
      146 1  146           3  0.99960464  1.20815553  1.964406259 -2.910955792
      147 5  147           4 -7.13179338 -2.19044540  0.525981588  2.420887883
      148 3  148           2 -2.08179444  0.02408655 -0.163568206  0.007280199
      149 3  149           3 -2.89336133 -0.25951100  2.178112057 -0.730327623
      150 1  150           2  1.00022544  1.50876740  0.626003545 -2.783407188
      151 4  151           4 -6.00907478 -1.74842082  1.327924729  2.104584759
      152 2  152           2 -0.78306098  2.08464709 -0.773201689 -1.623528127
      153 4  153           4 -4.35776911 -1.28670842  0.897897423  1.753944253
      154 2  154           2 -0.72415010  1.59936632  0.187929928 -1.839180189
      155 1  155           1  2.75398675  1.64683307  1.661021671 -2.241245058
      156 1  156           2  0.99963692  1.53060640  0.685466646 -2.142127460
      157 2  157           2 -1.18879137  1.00028882  0.738635484 -1.159136590
      158 4  158           4 -5.38959337 -0.24251617 -0.562918279  0.999854886
      159 2  159           3  0.18355138  0.79435627  1.987044688 -1.911237980
      160 3  160           4 -2.73724990 -1.36044280 -0.100885012  0.395251528
      161 4  161           4 -5.03547627 -1.67440275 -0.194505649  1.028570457
      162 4  162           3 -4.26860167 -1.04814323  1.044502052  0.991581741
      163 2  163           2  0.24891467  2.26721357  1.630199416 -1.897584183
      164 4  164           3 -5.03837461  0.60946340  1.331986640  0.851162682
      165 2  165           2 -0.87950732  1.98615929 -0.341353092 -1.018174264
      166 1  166           3  0.79433376  1.90192967  2.361117660 -2.558037359
      167 1  167           1  2.38019599  0.93495470 -0.364328435 -3.205524616
      168 2  168           3 -0.76373078  0.83688733  2.250141137 -1.588621152
      169 3  169           3 -2.03624644 -0.26671464  0.392210241 -0.053355345
      170 3  170           4 -3.54259320  0.32573994 -0.295432125  0.872347415
      171 4  171           3 -5.40485909 -0.98080473  1.199171252  0.911409307
      172 1  172           2  1.71143843  1.87959691 -0.757559166 -2.692313170
      173 2  173           2  0.53879774  1.88363711 -0.131195963 -1.214728491
      174 3  174           3 -2.89100079  0.14065491  1.038088176 -0.435848953
      175 2  175           3 -0.56642269  1.49301442  1.592262461 -1.343647275
      176 2  176           2  0.40079303  1.57711308  1.416843808 -1.403777990
      177 4  177           3 -5.27925360 -1.20785432  1.821896224  1.000425822
      178 2  178           3 -0.75059202  0.44221016  1.594600858 -1.653021760
      179 2  179           2  0.70923221  4.45625391  0.740952417 -1.230139691
      180 3  180           3 -3.27464568 -0.67812532  1.637310569 -0.218110122
      181 3  181           2 -3.03994957  0.25396424 -0.289409556 -0.052229520
      182 2  182           2 -0.52213086  1.21048415  0.946406107 -1.566948249
      183 3  183           3 -3.66421630 -0.08238487  1.431480518  0.782261620
      184 1  184           2  1.87084407  3.24017001  0.781029198 -2.796149925
      185 2  185           2 -0.65634977  1.71345793  0.226247459 -1.620865814
      186 4  186           4 -5.28821515 -1.49290669  0.884798340  1.227451164
      187 2  187           2 -1.53510715  2.47639701  0.594535515 -1.952849130
      188 3  188           3 -2.17743970 -0.72043996  0.101269080 -0.378950892
      189 3  189           3 -3.50617543  0.06480349  1.963890563 -0.067627595
      190 5  190           4 -7.46943182 -2.06123823  1.706363968  2.074061222
      191 4  191           3 -3.91557453 -1.63370530  1.075005732  0.525642093
      192 2  192           2 -0.41073335  0.44108556 -0.711487884 -1.496411932
      193 2  193           3 -0.47191738  0.34280678  0.734585562 -1.969340839
      194 2  194           3 -1.52759841  1.12598854  2.626502038 -1.440448658
      195 5  195           4 -5.92673585 -2.42752754  1.081821904  3.051306954
      196 3  196           3 -2.88224787 -0.89766565  0.996793803 -0.434312370
      197 2  197           3 -2.01900743  0.24961025  1.081558968 -0.762358042
      198 3  198           3 -2.28802808  0.72387470  1.750826186 -0.490454810
      199 1  199           1  1.40564210  1.23063387 -0.476659007 -2.717354207
      200 1  200           2  2.42022943  2.64167936  0.151120464 -2.442228663
             .pred_5
      1   -4.7934016
      2   -1.1954975
      3   -5.9456108
      4   -2.3443515
      5   -6.3830234
      6    2.3422910
      7    0.7859152
      8    2.2113962
      9   -3.0029964
      10  -0.8239196
      11   1.4569805
      12  -2.5511608
      13   0.9992921
      14  -2.4475402
      15  -2.6630701
      16  -2.1027172
      17  -6.0410389
      18  -3.2140425
      19  -2.4472989
      20  -4.7418037
      21  -2.6208106
      22  -4.2780577
      23  -2.1151014
      24  -0.4440679
      25  -4.5303737
      26   0.5130533
      27   0.2048143
      28  -4.2276832
      29   1.5024901
      30  -1.9101631
      31  -3.8988458
      32   1.0001360
      33  -4.8920980
      34   1.7070417
      35  -0.3319025
      36  -1.9180169
      37  -0.8441866
      38  -3.5381462
      39  -0.4943788
      40  -4.3264204
      41  -6.2822856
      42  -6.4818189
      43  -4.9136701
      44  -4.2281187
      45  -3.8753119
      46  -1.5743333
      47  -2.5774574
      48   0.8318619
      49  -3.6860842
      50  -0.8554050
      51  -2.2958102
      52   2.5539949
      53   1.7822904
      54  -3.4552771
      55  -0.5007872
      56  -2.2882432
      57   1.0001497
      58  -5.8866487
      59  -4.7712472
      60  -0.7782458
      61  -3.8658330
      62  -3.9031737
      63  -4.2149103
      64   2.4703779
      65  -3.4507735
      66  -1.2384611
      67  -4.6280657
      68  -0.1481974
      69  -6.2024267
      70  -4.4801664
      71   0.0940552
      72  -0.2375715
      73  -6.3398456
      74   1.9052373
      75   1.1963195
      76  -0.8118120
      77  -5.8665088
      78  -1.9039684
      79  -4.2546256
      80  -6.1510358
      81  -2.0345244
      82  -2.3405437
      83  -3.9497677
      84   1.9840312
      85  -3.7641430
      86  -4.0339841
      87  -2.1014150
      88  -2.9689957
      89  -1.3724091
      90  -2.9531558
      91  -1.0399258
      92   1.2623504
      93  -1.1334317
      94  -4.1923999
      95  -2.0977968
      96  -2.8296960
      97  -4.4118239
      98  -4.6977429
      99  -4.4344010
      100 -3.6582290
      101 -3.5310202
      102 -3.7307993
      103 -4.8332570
      104  1.6739789
      105 -6.4429549
      106 -2.5221976
      107 -1.7083522
      108 -5.1093796
      109 -1.9684651
      110  1.6529013
      111 -5.3682739
      112 -2.2629526
      113 -3.1228085
      114 -5.8877916
      115  1.8888863
      116 -4.3160602
      117  0.8602627
      118 -4.5656161
      119 -5.6329720
      120  2.3672977
      121 -6.9172245
      122 -3.6861711
      123 -1.0356538
      124 -1.6476513
      125 -4.2009520
      126 -3.4751836
      127  1.8636391
      128 -1.9335786
      129 -4.9434057
      130 -2.8578393
      131  0.1980603
      132 -4.1199714
      133 -2.4792999
      134  0.8197360
      135 -0.7908653
      136  2.1466409
      137 -4.9679698
      138  1.6631493
      139  1.5592701
      140 -2.6088195
      141 -5.3859433
      142 -0.6688420
      143 -2.1969972
      144  2.0528723
      145 -1.0455095
      146 -5.2114674
      147  1.5816924
      148 -2.8633758
      149 -1.6190651
      150 -5.4255995
      151 -0.3981105
      152 -4.4613909
      153 -0.1881223
      154 -4.0596828
      155 -5.8520247
      156 -5.0503196
      157 -4.2604565
      158 -0.7306453
      159 -3.2201399
      160 -1.5537384
      161 -0.9714674
      162 -0.8566286
      163 -4.9986469
      164 -0.7724413
      165 -4.3215386
      166 -5.7351114
      167 -6.3802661
      168 -4.0594844
      169 -2.8413809
      170 -0.9865164
      171 -0.1118636
      172 -4.9844625
      173 -3.0748388
      174 -2.2600763
      175 -3.3533208
      176 -3.7554597
      177 -0.2609647
      178 -3.9369549
      179 -4.6504858
      180 -1.6988371
      181 -2.7865314
      182 -3.5315299
      183 -0.4708590
      184 -5.1955996
      185 -4.4119116
      186  0.1214485
      187 -4.5774104
      188 -2.1771323
      189 -0.9335784
      190  1.1918093
      191 -1.4679164
      192 -3.7671437
      193 -4.2751056
      194 -3.7178419
      195  1.7513407
      196 -2.2348421
      197 -2.6675942
      198 -2.8436536
      199 -5.8364916
      200 -5.3823466

# `misvm()` examples work

    Code
      set.seed(8)
      mil_data <- generate_mild_df(nbag = 20, positive_prob = 0.15, sd_of_mean = rep(
        0.1, 3))
      df <- build_instance_feature(mil_data, seq(0.05, 0.95, length.out = 10))
      mdl1 <- misvm(x = df[, 4:123], y = df$bag_label, bags = df$bag_name, method = "heuristic")
      mdl2 <- misvm(mi(bag_label, bag_name) ~ X1_mean + X2_mean + X3_mean, data = df)
      if (require(gurobi)) {
        mdl3 <- misvm(x = df[, 4:123], y = df$bag_label, bags = df$bag_name, method = "mip")
      }
      predict(mdl1, new_data = df, type = "raw", layer = "bag")
    Output
      # A tibble: 80 x 1
         .pred
         <dbl>
       1 -1.04
       2 -1.04
       3 -1.04
       4 -1.04
       5  1.00
       6  1.00
       7  1.00
       8  1.00
       9 -1.00
      10 -1.00
      # ... with 70 more rows
    Code
      df %>% bind_cols(predict(mdl2, df, type = "class")) %>% bind_cols(predict(mdl2,
        df, type = "raw")) %>% distinct(bag_name, bag_label, .pred_class, .pred)
    Output
         bag_label bag_name .pred_class       .pred
      1          0     bag1           0 -0.11805071
      2          1     bag2           1  1.01732791
      3          0     bag3           0 -0.24540426
      4          1     bag4           1  1.00046917
      5          0     bag5           1  0.15460188
      6          0     bag6           1  0.87469487
      7          1     bag7           1  0.16754553
      8          0     bag8           1  1.00811386
      9          1     bag9           1  0.99998275
      10         1    bag10           1  2.67168111
      11         1    bag11           1  0.29471379
      12         0    bag12           1  1.52487131
      13         1    bag13           1  2.15326561
      14         1    bag14           1  0.99956477
      15         1    bag15           0 -0.38940230
      16         1    bag16           1  0.67654218
      17         0    bag17           1  0.39241276
      18         1    bag18           0 -0.11878006
      19         0    bag19           1  0.06554383
      20         1    bag20           1  0.85951804

# `omisvm()` examples work

    Code
      data("ordmvnorm")
      x <- ordmvnorm[, 4:8]
      y <- ordmvnorm$inst_label
      bags <- ordmvnorm$bag_name
      mdl1 <- omisvm(x, y, bags, weights = NULL)
      predict(mdl1, x, new_bags = bags)
    Output
      # A tibble: 1,000 x 1
         .pred_class
         <fct>      
       1 2          
       2 2          
       3 2          
       4 2          
       5 2          
       6 4          
       7 4          
       8 4          
       9 4          
      10 4          
      # ... with 990 more rows
    Code
      df1 <- bind_cols(y = y, bags = bags, as.data.frame(x))
      df1 %>% bind_cols(predict(mdl1, df1, new_bags = bags, type = "class")) %>%
        bind_cols(predict(mdl1, df1, new_bags = bags, type = "raw")) %>% distinct(y,
        bags, .pred_class, .pred)
    Output
          y bags .pred_class       .pred
      1   2    1           2 -1.03645764
      2   4    2           4  3.67601396
      3   1    3           1 -2.39973196
      4   3    4           3  0.66906606
      5   1    5           1 -3.48246909
      6   5    6           5  6.85206218
      7   4    7           4  4.66886871
      8   4    8           5  5.24915778
      9   3    9           3  0.54864346
      10  4   10           4  3.72408542
      11  5   11           5  5.98160166
      12  3   12           3  1.27551654
      13  5   13           5  5.14693076
      14  3   14           3  0.60561694
      15  2   15           2 -0.31198426
      16  3   16           3  1.77021658
      17  2   17           1 -2.58626531
      18  2   18           2 -0.72551185
      19  2   19           2 -0.30356881
      20  1   20           2 -1.74629058
      21  3   21           3  1.61067634
      22  2   22           2 -0.95614256
      23  3   23           3  0.56172112
      24  4   24           4  3.67810268
      25  2   25           2 -1.03409207
      26  4   26           4  4.30641029
      27  4   27           4  3.88594951
      28  2   28           2 -1.26325221
      29  5   29           5  6.47651693
      30  3   30           3  2.19631609
      31  2   31           2 -0.52759631
      32  5   32           5  4.84912924
      33  2   33           2 -0.92260752
      34  5   34           5  5.87016909
      35  4   35           4  3.20097629
      36  3   36           3  1.43210242
      37  4   37           4  3.35592486
      38  2   38           2 -0.45527932
      39  4   39           4  3.12729707
      40  2   40           2 -0.74573847
      41  1   41           1 -3.43331721
      42  1   42           1 -4.28071663
      43  2   43           2 -1.44759334
      44  2   44           2 -1.88278852
      45  2   45           2 -0.87339657
      46  3   46           4  2.82729795
      47  3   47           3  1.31684879
      48  4   48           4  3.84808978
      49  2   49           2 -0.67852382
      50  4   50           4  3.02828586
      51  3   51           3  2.26216806
      52  5   52           5  7.02630364
      53  5   53           5  5.84808978
      54  2   54           2  0.12398886
      55  4   55           4  3.53609601
      56  3   56           3  0.43115344
      57  5   57           5  5.82582754
      58  1   58           1 -2.91808511
      59  2   59           2 -1.56196942
      60  4   60           4  4.78096969
      61  2   61           2 -0.88131754
      62  2   62           2 -1.05864141
      63  2   63           2 -0.65762928
      64  5   64           5  6.87318351
      65  2   65           2 -0.08486045
      66  4   66           4  3.48920931
      67  2   67           2 -1.08772147
      68  4   68           4  4.61085584
      69  1   69           1 -3.27766494
      70  2   70           2 -1.09349346
      71  4   71           5  5.19942023
      72  4   72           4  3.91143803
      73  1   73           1 -3.39679396
      74  5   74           5  6.21800752
      75  5   75           5  6.59934220
      76  4   76           4  4.21965546
      77  1   77           1 -3.61257710
      78  3   78           3  2.18824343
      79  2   79           2 -0.94800466
      80  1   80           1 -3.34191415
      81  3   81           3  1.17351766
      82  3   82           3  1.63360881
      83  2   83           2 -0.90182698
      84  5   84           5  6.69063297
      85  2   85           2 -0.74593471
      86  2   86           2 -1.46190047
      87  3   87           3  1.61845884
      88  3   88           3  0.85944472
      89  3   89           3  1.77674981
      90  2   90           2 -0.74029426
      91  3   91           3  2.62857382
      92  4   92           4  4.82639322
      93  3   93           3  2.07693480
      94  2   94           2 -0.07774251
      95  3   95           3  0.95865641
      96  3   96           2  0.29102504
      97  2   97           2 -1.08745913
      98  2   98           2 -1.72896321
      99  2   99           2 -0.47375393
      100 2  100           2 -0.51347326
      101 2  101           2 -1.02409550
      102 2  102           2 -0.78363088
      103 2  103           2 -1.11474697
      104 5  104           5  6.68836567
      105 1  105           1 -4.40466443
      106 3  106           3  2.05882500
      107 3  107           3  1.53542643
      108 1  108           1 -3.73801000
      109 3  109           3  1.37283206
      110 5  110           5  5.98927588
      111 1  111           1 -2.59476689
      112 3  112           3  1.67601396
      113 2  113           3  0.32725370
      114 1  114           1 -3.22701380
      115 5  115           5  7.23305016
      116 2  116           2 -1.29687250
      117 4  117           4  4.72568606
      118 2  118           2 -1.52665451
      119 1  119           1 -3.33832218
      120 5  120           5  7.35277799
      121 1  121           1 -3.89883787
      122 2  122           2 -1.10402996
      123 3  123           3  2.08124076
      124 3  124           3  1.01841210
      125 2  125           2 -0.93044046
      126 2  126           2 -0.25415027
      127 5  127           5  5.74489746
      128 3  128           3  2.45294575
      129 1  129           1 -2.91908636
      130 3  130           3  1.79961508
      131 4  131           4  3.84808978
      132 2  132           2 -1.04694947
      133 3  133           3  1.73008186
      134 5  134           4  4.77863112
      135 4  135           4  3.73649013
      136 5  136           5  6.71149129
      137 2  137           2 -1.60379410
      138 5  138           5  6.08686291
      139 5  139           5  5.72960918
      140 3  140           3  1.26394942
      141 2  141           2 -0.93596503
      142 3  142           3  2.01834709
      143 3  143           3  1.30411824
      144 5  144           5  7.19100262
      145 4  145           4  2.78819872
      146 1  146           1 -2.93401437
      147 5  147           5  6.17503412
      148 3  148           3  1.27877836
      149 3  149           3  1.00331346
      150 1  150           1 -2.90648220
      151 4  151           5  5.06292059
      152 2  152           2 -0.88723773
      153 4  153           4  4.48085131
      154 2  154           2 -1.03169302
      155 1  155           1 -2.09828380
      156 1  156           1 -2.14410052
      157 2  157           2 -0.09539716
      158 4  158           4  3.47044952
      159 2  159           2 -1.08462208
      160 3  160           3  2.49654798
      161 4  161           4  3.37566435
      162 4  162           4  3.21585144
      163 2  163           2 -1.62527180
      164 4  164           4  3.24866124
      165 2  165           2 -0.33296895
      166 1  166           1 -2.91944488
      167 1  167           1 -3.85670460
      168 2  168           2 -0.76048390
      169 3  169           3  1.68132921
      170 3  170           4  2.88658521
      171 4  171           4  3.66708613
      172 1  172           1 -2.62086687
      173 2  173           2 -0.02648278
      174 3  174           3  1.29779306
      175 2  175           2  0.07315978
      176 2  176           2 -0.66975986
      177 4  177           4  3.22145269
      178 2  178           2 -0.67737919
      179 2  179           2 -0.75692270
      180 3  180           3  1.60128830
      181 3  181           3  1.67601396
      182 2  182           2 -0.56794762
      183 3  183           4  3.12491993
      184 1  184           1 -2.84848850
      185 2  185           2 -1.18040065
      186 4  186           4  3.91549752
      187 2  187           2 -1.63209471
      188 3  188           3  1.21713131
      189 3  189           3  2.19160794
      190 5  190           5  5.70852538
      191 4  191           4  3.10103175
      192 2  192           2 -1.01826165
      193 2  193           2 -1.27670617
      194 2  194           2 -0.67425800
      195 5  195           5  6.49666575
      196 3  196           3  1.23162218
      197 2  197           3  0.33159205
      198 3  198           3  1.34725037
      199 1  199           1 -2.89136053
      200 1  200           1 -2.28702808

# `smm()` examples work

    Code
      set.seed(8)
      n_instances <- 10
      n_samples <- 20
      y <- rep(c(1, -1), each = n_samples * n_instances / 2)
      instances <- as.character(rep(1:n_instances, each = n_samples))
      x <- data.frame(x1 = rnorm(length(y), mean = 1 * (y == 1)), x2 = rnorm(length(y),
      mean = 2 * (y == 1)), x3 = rnorm(length(y), mean = 3 * (y == 1)))
      df <- data.frame(instance_name = instances, y = y, x)
      mdl <- smm(x, y, instances)
      mdl2 <- smm(y ~ ., data = df)
      df %>% dplyr::bind_cols(predict(mdl, type = "raw", new_data = x, new_instances = instances)) %>%
        dplyr::bind_cols(predict(mdl, type = "class", new_data = x, new_instances = instances)) %>%
        dplyr::distinct(instance_name, y, .pred, .pred_class)
    Output
         instance_name  y      .pred .pred_class
      1              1  1  1.0000000           1
      2              2  1  0.9038444           1
      3              3  1  1.1047533           1
      4              4  1  0.9112317           1
      5              5  1  0.8965109           1
      6              6 -1 -1.1437942          -1
      7              7 -1 -1.0000000          -1
      8              8 -1 -1.0679171          -1
      9              9 -1 -1.1645562          -1
      10            10 -1 -1.2293499          -1

# `summarize_samples()` examples work

    Code
      fns <- list(mean = mean, sd = sd)
      suppressMessages({
        summarize_samples(mtcars, group_cols = c("cyl", "gear"), .fns = fns) %>%
          print()
        summarize_samples(mtcars, group_cols = c("cyl", "gear"), .fns = fns, cor = TRUE) %>%
          print()
      })
    Output
      # A tibble: 8 x 20
          cyl  gear mpg_mean disp_mean hp_mean drat_mean wt_mean qsec_mean vs_mean
        <dbl> <dbl>    <dbl>     <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>
      1     4     3     21.5      120.     97       3.7     2.46      20.0     1  
      2     4     4     26.9      103.     76       4.11    2.38      19.6     1  
      3     4     5     28.2      108.    102       4.1     1.83      16.8     0.5
      4     6     3     19.8      242.    108.      2.92    3.34      19.8     1  
      5     6     4     19.8      164.    116.      3.91    3.09      17.7     0.5
      6     6     5     19.7      145     175       3.62    2.77      15.5     0  
      7     8     3     15.0      358.    194.      3.12    4.10      17.1     0  
      8     8     5     15.4      326     300.      3.88    3.37      14.6     0  
      # ... with 11 more variables: am_mean <dbl>, carb_mean <dbl>, mpg_sd <dbl>,
      #   disp_sd <dbl>, hp_sd <dbl>, drat_sd <dbl>, wt_sd <dbl>, qsec_sd <dbl>,
      #   vs_sd <dbl>, am_sd <dbl>, carb_sd <dbl>
      # A tibble: 8 x 56
          cyl  gear mpg_mean disp_mean hp_mean drat_mean wt_mean qsec_mean vs_mean
        <dbl> <dbl>    <dbl>     <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>
      1     4     3     21.5      120.     97       3.7     2.46      20.0     1  
      2     4     4     26.9      103.     76       4.11    2.38      19.6     1  
      3     4     5     28.2      108.    102       4.1     1.83      16.8     0.5
      4     6     3     19.8      242.    108.      2.92    3.34      19.8     1  
      5     6     4     19.8      164.    116.      3.91    3.09      17.7     0.5
      6     6     5     19.7      145     175       3.62    2.77      15.5     0  
      7     8     3     15.0      358.    194.      3.12    4.10      17.1     0  
      8     8     5     15.4      326     300.      3.88    3.37      14.6     0  
      # ... with 47 more variables: am_mean <dbl>, carb_mean <dbl>, mpg_sd <dbl>,
      #   disp_sd <dbl>, hp_sd <dbl>, drat_sd <dbl>, wt_sd <dbl>, qsec_sd <dbl>,
      #   vs_sd <dbl>, am_sd <dbl>, carb_sd <dbl>, cov_var_1 <dbl>, cov_var_2 <dbl>,
      #   cov_var_3 <dbl>, cov_var_4 <dbl>, cov_var_5 <dbl>, cov_var_6 <dbl>,
      #   cov_var_7 <dbl>, cov_var_8 <dbl>, cov_var_9 <dbl>, cov_var_10 <dbl>,
      #   cov_var_11 <dbl>, cov_var_12 <dbl>, cov_var_13 <dbl>, cov_var_14 <dbl>,
      #   cov_var_15 <dbl>, cov_var_16 <dbl>, cov_var_17 <dbl>, cov_var_18 <dbl>, ...

# `svor_exc()` examples work

    Code
      data("ordmvnorm")
      x <- ordmvnorm[, 4:8]
      y <- ordmvnorm$inst_label
      mdl1 <- svor_exc(x, y)
    Message <message>
      The SMO algorithm reached the maximum of 500 steps.
    Code
      predict(mdl1, x)
    Output
      # A tibble: 1,000 x 1
         .pred_class
         <fct>      
       1 5          
       2 1          
       3 1          
       4 1          
       5 2          
       6 1          
       7 5          
       8 5          
       9 5          
      10 5          
      # ... with 990 more rows
    Code
      predict(mdl1, x, type = "raw")
    Output
      # A tibble: 1,000 x 1
           .pred
           <dbl>
       1  0.215 
       2 -0.445 
       3 -0.644 
       4 -0.320 
       5 -0.0253
       6 -0.269 
       7  0.814 
       8  0.705 
       9  0.367 
      10  0.400 
      # ... with 990 more rows

